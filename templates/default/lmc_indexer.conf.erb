input {
  rabbitmq {
    ack => true
    host => 'localhost'
    port => <%= node[:logstash][:broker][:port] %>
    exchange => "logstash"
    user => "<%= node[:rabbitmq][:default_user] %>"
    password => "<%= node[:rabbitmq][:default_pass] %>"
    ssl => <%=  node[:logstash][:ssl][:enabled] %>
  }
}

filter {
  if [type] == "apache-access" {
    # apache-access logs
    grok {
      patterns_dir => "<%= @patterns_dir %>"
      match => [ "message", "%{APACHE_LMC_ACCESS_LOG}" ]
    }
    mutate {
      convert => [ "responsetime", "integer" ]
      convert => [ "bytes", "integer" ]
    }
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      remove_field => [ "timestamp" ]
    }
    geoip {
      add_tag => [ "geoip" ]
      source => "clientip"
    }

    # create coords array with long and lat
    mutate {
      add_field => [ "coords", "%{[geoip][longitude]}",
                     "tmplat", "%{[geoip][latitude]}" ]
      merge => [ "coords", "tmplat" ]
      remove_field => "tmplat"
      convert => [ "coords", "float" ]
    }
  }
  if [type] == "postgresql" {
    grok {
      match => ["message", "%{DATESTAMP:timestamp} %{TZ} %{DATA:event_type}: %{GREEDYDATA:data}"]
    }
    # Error events can be multiline (can include detail and statement)
    if [event_type] == "ERROR" {
      grok {
        add_tag => ["error"]
        # Ok, here we will extrate the error message, detail, and statement (detail and statement may or may not be there)
        # we also remove the 'data' field, error_message will replace it
        remove_field => ["data"]
        match => ["message", "%{TIMESTAMP_ISO8601}.+ERROR:\s+%{DATA:error_message}(\s*%{TIMESTAMP_ISO8601}.+DETAIL:\s+%{DATA:test})?(\s*%{TIMESTAMP_ISO8601}.+STATEMENT:\s+%{DATA:statement})?$"]
      }
    }
  }
}


output {
  stdout {  }

  elasticsearch {
    host => "localhost"
  }
}